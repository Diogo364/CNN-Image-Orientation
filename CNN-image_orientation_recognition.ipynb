{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Orientation Recognition using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4KggQEk9TfBu",
    "outputId": "1be46052-bf20-4119-d72e-a5c9fcdeacf6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paths\n",
    "---\n",
    "This variables will be used throughout our code to improve readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "train_path = os.path.join(project_root, 'data_set', 'train', 'train')\n",
    "test_path = os.path.join(project_root, 'data_set', 'test')\n",
    "target_path = os.path.join(project_root, 'target')\n",
    "checkpoint_path = os.path.join(project_root, 'model_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Test Labels DataFrame\n",
    "---\n",
    "\n",
    "This is a DataFrame that contains the name and the label of each train image as following:\n",
    "``` \n",
    "{\n",
    "    'fn': filename,\n",
    "    'label': label\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-10049200_1891-09-16_1958.jpg</td>\n",
       "      <td>rotated_left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-10110600_1985-09-17_2012.jpg</td>\n",
       "      <td>rotated_left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-10126400_1964-07-07_2010.jpg</td>\n",
       "      <td>upright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-1013900_1917-10-15_1960.jpg</td>\n",
       "      <td>rotated_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-10166400_1960-03-12_2008.jpg</td>\n",
       "      <td>upside_down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fn          label\n",
       "0  0-10049200_1891-09-16_1958.jpg   rotated_left\n",
       "1  0-10110600_1985-09-17_2012.jpg   rotated_left\n",
       "2  0-10126400_1964-07-07_2010.jpg        upright\n",
       "3   0-1013900_1917-10-15_1960.jpg  rotated_right\n",
       "4  0-10166400_1960-03-12_2008.jpg    upside_down"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(f'{train_path}/../train.truth.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Implementation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting frequent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #This was arbitrarily defined\n",
    "target_size = (64, 64) #This is the image resolution's 64x64 pixels\n",
    "num_classes = train_set.label.nunique()  #Number of unique labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training image set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow loads the training set, normalize it by dividing each value by 255 - that is the maximum possible value - and splits it into 'training' and 'validation' - 3:1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36672 validated image filenames belonging to 4 classes.\n",
      "Found 12224 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_set, \n",
    "    directory=train_path, \n",
    "    x_col=\"fn\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=target_size)\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_set, \n",
    "    directory=train_path, \n",
    "    x_col=\"fn\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test image set\n",
    "---\n",
    "As it doesn't has labels we used the `flow_from_directory` method. pointing only the directory of images.\n",
    "\n",
    "**Important:** It is important to Normalize this data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5361 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plans all the CNN layer structure and its 'functionalities'.\n",
    "\n",
    "Basically implements an sequential Neural Network that will compares pixels in a positional way and apply some calculation on it to try to compute the probability on each pixel set to belong to any of our classes.\n",
    "\n",
    "For a complete understanding of each function and method used here I recomend watching the [Tensorflow tutorial](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ) provided by Hvass Laboratories and available on YouTube. It consists on a playlist teaching all the practical aspects of creating this CNN Network and it is applied on CIFAR-10  and MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSGTTOvddaS2"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(batch_size, (3, 3), padding='same',\n",
    "                 input_shape=train_generator[0][0].shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(batch_size, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(batch_size*2, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(batch_size*2, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to see a draft of the layers execute the cell bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting proper step size for each dataset\n",
    "---\n",
    "This variables contains the size of each executable fraction that will be feeded to our model at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of epochs was also arbitrarily defined. As you can see in the outputed cell, each epoch took at least900 seconds to be completed and the entropy lost decay rate - that is our evaluation metric to be minimized - began very low from the 8th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-7a6ea1463e5a>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "1146/1146 [==============================] - 957s 835ms/step - loss: 0.5513 - accuracy: 0.7832 - val_loss: 0.2503 - val_accuracy: 0.9115\n",
      "Epoch 2/10\n",
      "1146/1146 [==============================] - 922s 805ms/step - loss: 0.2145 - accuracy: 0.9230 - val_loss: 0.1526 - val_accuracy: 0.9463\n",
      "Epoch 3/10\n",
      "1146/1146 [==============================] - 938s 819ms/step - loss: 0.1390 - accuracy: 0.9520 - val_loss: 0.1065 - val_accuracy: 0.9631\n",
      "Epoch 4/10\n",
      "1146/1146 [==============================] - 910s 794ms/step - loss: 0.1075 - accuracy: 0.9630 - val_loss: 0.1002 - val_accuracy: 0.9653\n",
      "Epoch 5/10\n",
      "1146/1146 [==============================] - 905s 789ms/step - loss: 0.0902 - accuracy: 0.9701 - val_loss: 0.0804 - val_accuracy: 0.9701\n",
      "Epoch 6/10\n",
      "1146/1146 [==============================] - 904s 789ms/step - loss: 0.0774 - accuracy: 0.9729 - val_loss: 0.0772 - val_accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "1146/1146 [==============================] - 900s 785ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
      "Epoch 8/10\n",
      "1146/1146 [==============================] - 905s 790ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0659 - val_accuracy: 0.9755\n",
      "Epoch 9/10\n",
      "1146/1146 [==============================] - 902s 787ms/step - loss: 0.0590 - accuracy: 0.9796 - val_loss: 0.0648 - val_accuracy: 0.9759\n",
      "Epoch 10/10\n",
      "1146/1146 [==============================] - 901s 786ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.0664 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff576747290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    epochs=10 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained model\n",
    "---\n",
    "This was implemented to avoid having to train our model every time we need to use it.\n",
    "It also can be used as an checkpoint to improve our model and run more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/diogotelheirodonascimento/Desktop/DeeperSystem/test2/model_checkpoint/CNN-Photo_orientation/assets\n",
      "Saved trained model at /Users/diogotelheirodonascimento/Desktop/DeeperSystem/test2/model_checkpoint/CNN-Photo_orientation \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights into checkpoint directory\n",
    "model_name = 'CNN-Photo_orientation'\n",
    "model_path = os.path.join(checkpoint_path, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model using validation set\n",
    "---\n",
    "Now we evaluate our accuracy on our validation set. We would like to run on our entire set, so we need to redifine our `batch_size` and `our STEP_SIZE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0I9v4A8dZ6K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12224/12224 [==============================] - 150s 12ms/step - loss: 0.0664 - accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06644802540540695, 0.9761943817138672]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "valid_generator.batch_size = 1\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.evaluate(valid_generator, steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 97% in our first attempt to create this kind of model works very fine by me at this point, as it was not provided an minimum accepted accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the orientation on each test file\n",
    "---\n",
    "Now we want to use our model to predict the class of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5361/5361 [==============================] - 58s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5361, 4)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to notice that the output of or CNN is an probability array of shape (n, y) in which:\n",
    "- n is the number of images\n",
    "- y consists on the probability of belonging to each of the 4 classes\n",
    "\n",
    "Having said so we need to compute the 'real class' for each image.\n",
    "To do so we just select the highest probability on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "predicted_class_indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VdgQHojdZ0l"
   },
   "outputs": [],
   "source": [
    "'''Here we just are creating an `labels` dictionary to convert \n",
    "one-hot-encoded array to our class label'''\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "#Here we create an list with the real class label\n",
    "predictions = [labels[k] for k in predicted_class_indices] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions DataFrame\n",
    "---\n",
    "To submit our results we will generate an DataFrame in the same format that was provided to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6mWTYixdZyI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5361, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_set/90-10184590_1979-06-16_2006.jpg</td>\n",
       "      <td>rotated_left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_set/90-1019890_1931-08-10_1978.jpg</td>\n",
       "      <td>upright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_set/90-10241990_1984-11-28_2007.jpg</td>\n",
       "      <td>rotated_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_set/90-102690_1966-09-09_2011.jpg</td>\n",
       "      <td>rotated_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_set/90-10303590_1983-01-26_2010.jpg</td>\n",
       "      <td>rotated_right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         fn          label\n",
       "0  test_set/90-10184590_1979-06-16_2006.jpg   rotated_left\n",
       "1   test_set/90-1019890_1931-08-10_1978.jpg        upright\n",
       "2  test_set/90-10241990_1984-11-28_2007.jpg  rotated_right\n",
       "3    test_set/90-102690_1966-09-09_2011.jpg  rotated_right\n",
       "4  test_set/90-10303590_1983-01-26_2010.jpg  rotated_right"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"fn\":filenames,\n",
    "                      \"label\":predictions})\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(os.path.join(target_path,\"predictions.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Image Orientation\n",
    "---\n",
    "For this second part we will correct the orientation of each image no the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a copy of the Test set within the target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory already exists\n",
      "Rebooting directory...\n",
      "Finished\n",
      "0 files created!\n"
     ]
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "\n",
    "corrected_test_dir = os.path.join(target_path, 'corrected_test')\n",
    "if not os.path.isdir(corrected_test_dir):\n",
    "    print('creating directory')\n",
    "    os.mkdir(corrected_test_dir)\n",
    "    print('finished')\n",
    "else:\n",
    "    print('The directory already exists')\n",
    "\n",
    "print('Rebooting directory...')\n",
    "for filename in os.listdir(corrected_test_dir):\n",
    "    file_path = os.path.join(corrected_test_dir, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "# copy_tree(os.path.join(test_path, 'test_set'), corrected_test_dir)\n",
    "print('Clean Directory Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will iterate over the directory, open each image and rotate it as in our rotation_guide suggests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_guide = {\n",
    "    'upright': 0, \n",
    "    'rotated_right': 90, \n",
    "    'upside_down': 180,\n",
    "    'rotated_left': 270\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining correct orientation image routine\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from time import sleep\n",
    "\n",
    "verbose = False\n",
    "test_image_path = os.path.join(test_path, 'test_set')\n",
    "\n",
    "print('Begining correct orientation image routine')\n",
    "for n,image_name in enumerate(os.listdir(test_image_path)):\n",
    "    if verbose:\n",
    "        print(f'{n}/{len(os.listdir(test_image_path))}', end='\\r')\n",
    "        sleep(0.1)\n",
    "    image_path = os.path.join(test_image_path, image_name)\n",
    "    image_orientation = results.loc[results.fn.str.contains(image_name), 'label'].values[0]\n",
    "    assert len(image_orientation) > 0, 'No image found!'\n",
    "    assert len(image_orientation) > 1, f'Multiple images with same name! on name {image_name}'\n",
    "    image = Image.open(image_path)\n",
    "    rotated = image.rotate(rotation_guide[image_orientation])\n",
    "    rotated.save(os.path.join(corrected_test_dir, image_name.replace('.jpg', '.png')), format='png')\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5361"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(corrected_test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip Output\n",
    "Then we will Zip our corrected folder to submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile(f'{corrected_test_dir}.zip', \"w\")\n",
    "for dirname, subdirs, files in os.walk(corrected_test_dir):\n",
    "    zf.write(dirname)\n",
    "    for filename in files:\n",
    "        zf.write(os.path.join(dirname, filename))\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Numpy Output\n",
    "---\n",
    "For the last task we will save our corrected image in an numpy.array as it is required to work with other ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5361 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "correct_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "correct_generator=correct_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=len(os.listdir(corrected_test_dir)),\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_output = correct_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(target_path, 'numpy_output'), numpy_output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeeperSystems - Test2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}